{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper Functions to keep notebook clean\n",
    "import functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define file and folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + \"/\"\n",
    "\n",
    "PCD_folder = PATH + \"DATA/cifs/PCD/\"\n",
    "ICSD_folder = PATH + \"DATA/cifs/ICSD/\"\n",
    "\n",
    "PCD_pickle_raw = PATH + 'DATA/pickle/PCD_raw.pkl'\n",
    "ICSD_pickle_raw = PATH + 'DATA/pickle/ICSD_raw.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The PCD dataset was provided by our Assistant, which is why we didn't include the download for that*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a lot of data is necessary for this part, part of the data is downloaded from the ICSD database courtesy of FIZ Karlsruhe. This can be done via their API, where the script by github user \"simonverret\" was used: https://github.com/simonverret/materials_data_api_scripts. \n",
    "\n",
    "But since this script downloads the data into a `.csv` file and not `.cif` files (which will be important later down the line), the script was modified to suit our needs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logged in ICSD  (token=0BF8D8664C079C29AB4E276E0D525E4E)\n",
      "materials with 1 elements\n",
      "Progress: [---->] 100%\n",
      "received 3199/3199 cif strings\n",
      "materials with 2 elements\n",
      "Progress: [---------------------------------------------->] 100%\n",
      "received 46216/46216 cif strings\n",
      "materials with 3 elements\n",
      "Progress: [------------------------------------------------------------------------------------->] 100%\n",
      "received 85045/85045 cif strings\n",
      "materials with 4 elements\n",
      "Progress: [------------------------------------------------------------>] 100%\n",
      "received 60334/60334 cif strings\n",
      "materials with 5 elements\n",
      "Progress: [---------------------------------------->] 100%\n",
      "received 40133/40133 cif strings\n",
      "logged out ICSD (token=523FC3D1C4A4406837FD656353D1E2C0)\n"
     ]
    }
   ],
   "source": [
    "import ICSD_download as icd\n",
    "\n",
    "credentials = icd.get_credentials()\n",
    "icd.download_all(credentials[\"loginid\"], credentials[\"password\"], min_N = 1, max_N = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading all the `.cif` files, we want to convert the files into a `pandas.DataFrame` for easier data handling. Our 2 main objectives that we want to achieve to are:\n",
    "\n",
    "1. Calculate coefficient of thermal expansion\n",
    "2. Generate feature vectors\n",
    "\n",
    "Step 1 can be easily handled in a dataframe. Step 2 however, isn't as straightforward. For the feature vectors we want to use **pymatgen** which can load .cif files to create `pymatgen.core.Structure` objects, but when we do operations on the corresponding dataframe, those operations don't translate well and we might loose track of which exact `.cif` files should be loaded afterwards. To circumvent this problem, while creating the dataframe, we attach the `dict` version of the **pymatgen** object to the end, this way we can store all the raw data in one dataframe while also keeping data together when we perform row operations on the dataframe. This will however lead to additional complexity later down the line when we have to fetch the **pymatgen** object out of the dataframe, create the feature vectors and then merge them back in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we actually convert the PCD `.cif` files into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: PCD cifs\n",
      "Progress: [------------------->] 100%\n",
      "Final Report: 7% Failed to load, 144 minutes taken for entire operation\n"
     ]
    }
   ],
   "source": [
    "df_PCD_raw = func.load_PCD_cif(PCD_folder)\n",
    "\n",
    "df_PCD_raw.to_pickle(PCD_pickle_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a quick look at how large the useable raw PCD dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281865\n"
     ]
    }
   ],
   "source": [
    "print(len(df_PCD_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we convert the ICSD `.cif` files into a dataframe. \n",
    "\n",
    "**Note:** the `.cif` files downloaded from the ICSD database sometimes contain the ' (apostrophe) within the publication title. Because the `MMMCFI2Dict` module reads parts of the file according to the formatting, this messes with some of the files present. We went through the entire list and identified which files contained a loose apostrophe and removed it. If you try to replicate the results, be very mindful of this and maybe try to circumvent this problem from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ICSD cifs\n",
      "Progress: [------------------->] 100%\n",
      "Final Report: 2% Failed to load, 155 minutes taken for entire operation\n"
     ]
    }
   ],
   "source": [
    "df_ICSD_raw = func.load_ICSD_cif(ICSD_folder)\n",
    "\n",
    "df_ICSD_raw.to_pickle(ICSD_pickle_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a quick look at how large the useable raw ICSD dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229320\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ICSD_raw))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9390045621feb823ba4af5b6ebaa3f354f47709dd0151da338676d8e1b29f7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
